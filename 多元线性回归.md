# 载入数据
[50_Startups.csv](https://github.com/171909771/DATA-scientist/files/8983753/50_Startups.csv)
## 多元线性回归要满足
![image](https://user-images.githubusercontent.com/41554601/175755446-9051c9c5-842d-4c53-8df5-9db9e7c42461.png)
## 建立模型的方法
### 最常用的是反向淘汰
![image](https://user-images.githubusercontent.com/41554601/175755475-9115ee26-3834-4a6e-8ea6-795bc9f0606d.png)
```
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt 
datasets=pd.read_csv('50_Startups.csv')
X=datasets.iloc[:,:-1].values
Y=datasets.iloc[:,-1].values
# 转换分类变量
from sklearn.preprocessing import LabelEncoder
X[:,3]=LabelEncoder().fit_transform(X[:,3])
from sklearn.preprocessing import OneHotEncoder
test1=OneHotEncoder(dtype=np.int32).fit_transform(X[:,[3]]).toarray()
X=np.append(test1[:,1:],X[:,:-1],axis=1)
# 分数据集
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=0)
# 反向排除backward elimination
import statsmodels.api as sm
## 加入常变量，用1代替
X_train = sm.add_constant(X_train) # 相当于X_train=np.append(np.array([[1] for i in range(40)]),X_train,1)
X_opt=np.array(X_train[:,[0,1,2,3,4,5]], dtype=float)
regressor_OLS=sm.OLS(endog=y_train, exog=X_opt).fit()
regressor_OLS.summary()
## 循环做，查看p值小于0.05，就删除那一列，最终只留下小于0.05的
X_opt=np.array(X_train[:,[0,3]], dtype=float)
regressor_OLS=sm.OLS(endog=y_train, exog=X_opt).fit()
regressor_OLS.summary()
```
